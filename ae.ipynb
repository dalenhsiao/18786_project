{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "from typing import Counter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Use this if you are using any Cuda enabled system\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransMolecule(object):\n",
    "\n",
    "    def __init__(self, molecule_num=5):\n",
    "        self.molecule_num = molecule_num\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        num_atoms = sample.x.size(0)\n",
    "        edges = sample.edge_index\n",
    "        adj_matrix = torch.zeros(num_atoms, num_atoms)\n",
    "        for i in range(edges.size(1)):\n",
    "            start, end = edges[0][i], edges[1][i]\n",
    "            adj_matrix[start][end] = 1\n",
    "            adj_matrix[end][start] = 1\n",
    "\n",
    "        # fix size of adj_matrix 24 x 24\n",
    "        if num_atoms < 29:\n",
    "            adj_matrix = torch.cat((adj_matrix, torch.zeros(29 - num_atoms, num_atoms)), dim=0)\n",
    "            adj_matrix = torch.cat((adj_matrix, torch.zeros(29, 29 - num_atoms)), dim=1)\n",
    "\n",
    "        return adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n",
      "torch.Size([64, 29, 29])\n"
     ]
    }
   ],
   "source": [
    "data = QM9(root='./qm9_data', transform=TransMolecule())\n",
    "\n",
    "\"\"\"\n",
    "each batch is considered a hugh graph with many nodes and edges,\n",
    "in EGNN, they introduce the concept of l2 distance between nodes, \n",
    "yet I am not including this (probably not) for now. \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "dataloader = DataLoader(data, batch_size=64, shuffle=False) \n",
    "for i , x in enumerate(dataloader):\n",
    "    print(x.shape)\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Autoencoder(nn.Module):\n",
    "#     def __init__(self, latent_dim,hidden_dim,input_dim):\n",
    "#         super(Autoencoder, self).__init__()\n",
    "#         output_dim = input_dim\n",
    "#         #TODO\n",
    "#         self.encoder = Encoder(latent_dim,hidden_dim,input_dim)\n",
    "#         self.decoder = Decoder(latent_dim,hidden_dim,output_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         #TODO\n",
    "#         encoded = self.encoder(x)\n",
    "#         decoded = self.decoder(encoded)\n",
    "#         return decoded\n",
    "    \n",
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self, latent_dim,hidden_dim,input_dim):\n",
    "#         super(Encoder, self).__init__()\n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Linear(input_dim, hidden_dim),\n",
    "#             nn.LeakyReLU(),\n",
    "#             nn.Linear(hidden_dim, hidden_dim),\n",
    "#             nn.LeakyReLU(),\n",
    "#             nn.Linear(hidden_dim, latent_dim)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         return self.model(x)\n",
    "    \n",
    "\n",
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, latent_dim,hidden_dim,output_dim):\n",
    "#         super(Decoder, self).__init__()\n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Linear(latent_dim, hidden_dim),\n",
    "#             nn.LeakyReLU(),\n",
    "#             nn.Linear(hidden_dim, hidden_dim),\n",
    "#             nn.LeakyReLU(),\n",
    "#             nn.Linear(hidden_dim, output_dim),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.model(x)\n",
    "#         return x.view(x.size(0),5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 15]              90\n",
      "         LeakyReLU-2                   [-1, 15]               0\n",
      "            Linear-3                   [-1, 15]             240\n",
      "         LeakyReLU-4                   [-1, 15]               0\n",
      "            Linear-5                    [-1, 2]              32\n",
      "           Encoder-6                    [-1, 2]               0\n",
      "            Linear-7                   [-1, 15]              45\n",
      "         LeakyReLU-8                   [-1, 15]               0\n",
      "            Linear-9                   [-1, 15]             240\n",
      "        LeakyReLU-10                   [-1, 15]               0\n",
      "           Linear-11                    [-1, 5]              80\n",
      "          Sigmoid-12                    [-1, 5]               0\n",
      "          Decoder-13                    [-1, 5]               0\n",
      "================================================================\n",
      "Total params: 727\n",
      "Trainable params: 727\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# hidden_dim = 15\n",
    "# latent_dim = 2\n",
    "# n_epochs = 15 \n",
    "# from torchsummary import summary\n",
    "# autoencoder = Autoencoder(latent_dim, hidden_dim,5).to(device)\n",
    "# summary(autoencoder,(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        #TODO\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, 3, stride=2, padding=0), # 1x29x29 -> 4x14x14\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(4, 8, 3, stride=1, padding=1), # 4x14x14 -> 8x14x14\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, stride=2), # 8x14x14 -> 8x7x7\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=0), # 8x7x7 -> 16x3x3\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(16, 32, 3, stride=1, padding=0), # 16x3x3 -> 32x1x1\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=0, output_padding=0), # 32x1x1 -> 16x3x3\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=0, output_padding=0), # 16x3x3 -> 8x7x7\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True), # 8x7x7 -> 8x14x14\n",
    "            nn.ConvTranspose2d(8, 4, 3, stride=1, padding=1), # 8x14x14 -> 4x14x14\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(4, 1, 3, stride=2, padding=0, output_padding=0), # 4x14x14 -> 1x29x29\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #TODO\n",
    "        # print(\"shape in autoencoder\", x.shape) # torch.Size([1, 1, 5, 5])\n",
    "        x = self.encoder(x)\n",
    "        # print(\"shape after encoder\", x.shape)\n",
    "        x = self.decoder(x)\n",
    "        # print(\"shape after decoder\", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 4, 14, 14]              40\n",
      "         LeakyReLU-2            [-1, 4, 14, 14]               0\n",
      "            Conv2d-3            [-1, 8, 14, 14]             296\n",
      "         LeakyReLU-4            [-1, 8, 14, 14]               0\n",
      "         MaxPool2d-5              [-1, 8, 7, 7]               0\n",
      "            Conv2d-6             [-1, 16, 3, 3]           1,168\n",
      "         LeakyReLU-7             [-1, 16, 3, 3]               0\n",
      "            Conv2d-8             [-1, 32, 1, 1]           4,640\n",
      "         LeakyReLU-9             [-1, 32, 1, 1]               0\n",
      "  ConvTranspose2d-10             [-1, 16, 3, 3]           4,624\n",
      "        LeakyReLU-11             [-1, 16, 3, 3]               0\n",
      "  ConvTranspose2d-12              [-1, 8, 7, 7]           1,160\n",
      "        LeakyReLU-13              [-1, 8, 7, 7]               0\n",
      "         Upsample-14            [-1, 8, 14, 14]               0\n",
      "  ConvTranspose2d-15            [-1, 4, 14, 14]             292\n",
      "        LeakyReLU-16            [-1, 4, 14, 14]               0\n",
      "  ConvTranspose2d-17            [-1, 1, 29, 29]              37\n",
      "          Sigmoid-18            [-1, 1, 29, 29]               0\n",
      "================================================================\n",
      "Total params: 12,257\n",
      "Trainable params: 12,257\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.09\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "autoencoder = Autoencoder()\n",
    "n_epochs = 25\n",
    "summary(autoencoder,(1,29,29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.007309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.007169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 0.007103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 0.007008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m output \u001b[38;5;241m=\u001b[39m autoencoder(x)\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, x)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/18786/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/18786/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "criterion = nn.MSELoss() # Loss function\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001) # Optimizer\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0\n",
    "    # Wrap your dataloader with tqdm to add a progress bar\n",
    "    for x in tqdm(dataloader, desc=f'Epoch {epoch + 1}/{n_epochs}', leave=False):\n",
    "        x = x.to(device)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # If x has a shape of odd number, pad it with zeros\n",
    "        # if x.shape[2] % 2 != 0:\n",
    "        #     x = nn.ZeroPad2d((0, 1, 0, 1))(x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = autoencoder(x)\n",
    "        loss = criterion(output, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    print(f'Epoch: {epoch + 1} \\tTraining Loss: {train_loss:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symetic_matrix(matrix):\n",
    "    n = matrix.shape[0]\n",
    "    output = torch.zeros(n, n)\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            if i == j:\n",
    "                continue\n",
    "            result = 1 if matrix[i][j] + matrix[j][i] > 0.5 else 0\n",
    "            output[i][j] = result\n",
    "            output[j][i] = result\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total edge in input tensor(8.)\n",
      "total edge in output tensor(8.)\n",
      "4.0\n",
      "total edge in input tensor(6.)\n",
      "total edge in output tensor(4.)\n",
      "1.0\n",
      "total edge in input tensor(4.)\n",
      "total edge in output tensor(4.)\n",
      "0.0\n",
      "total edge in input tensor(6.)\n",
      "total edge in output tensor(6.)\n",
      "4.0\n",
      "total edge in input tensor(4.)\n",
      "total edge in output tensor(4.)\n",
      "0.0\n",
      "total edge in input tensor(6.)\n",
      "total edge in output tensor(4.)\n",
      "1.0\n",
      "total edge in input tensor(14.)\n",
      "total edge in output tensor(10.)\n",
      "12.0\n",
      "total edge in input tensor(10.)\n",
      "total edge in output tensor(6.)\n",
      "4.0\n",
      "total edge in input tensor(12.)\n",
      "total edge in output tensor(16.)\n",
      "8.0\n",
      "total edge in input tensor(10.)\n",
      "total edge in output tensor(4.)\n",
      "5.0\n",
      "total edge in input tensor(12.)\n",
      "total edge in output tensor(6.)\n",
      "7.0\n",
      "total edge in input tensor(10.)\n",
      "total edge in output tensor(4.)\n",
      "5.0\n",
      "total edge in input tensor(20.)\n",
      "total edge in output tensor(22.)\n",
      "9.0\n",
      "total edge in input tensor(16.)\n",
      "total edge in output tensor(14.)\n",
      "11.0\n",
      "total edge in input tensor(16.)\n",
      "total edge in output tensor(20.)\n",
      "6.0\n",
      "total edge in input tensor(18.)\n",
      "total edge in output tensor(12.)\n",
      "9.0\n",
      "total edge in input tensor(14.)\n",
      "total edge in output tensor(8.)\n",
      "5.0\n",
      "total edge in input tensor(18.)\n",
      "total edge in output tensor(18.)\n",
      "8.0\n",
      "total edge in input tensor(16.)\n",
      "total edge in output tensor(14.)\n",
      "9.0\n",
      "total edge in input tensor(14.)\n",
      "total edge in output tensor(14.)\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# print latent space\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for i in range(20):\n",
    "    x = data[i].to(device)\n",
    "    x = x.unsqueeze(0)\n",
    "    x = x.unsqueeze(0)\n",
    "    # print(x)\n",
    "    encoded = autoencoder.encoder(x)\n",
    "    decoded = autoencoder.decoder(encoded)\n",
    "    encoded = encoded.view(-1)\n",
    "    # print(encoded)\n",
    "    decoded = decoded.view(29, 29)\n",
    "    decoded = symetic_matrix(decoded)\n",
    "    print(\"total edge in input\", torch.sum(x) // 2)\n",
    "    print(\"total edge in output\", torch.sum(decoded) // 2)\n",
    "    print(np.sum(np.abs(x.detach().numpy() - decoded.detach().numpy())) // 2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "18786",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
