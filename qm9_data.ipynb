{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from test_model import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = T.Compose([MyTransform(), Complete(), T.Distance(norm=False)])\n",
    "\n",
    "data = QM9(root='./practice_data', transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[580, 11], edge_index=[2, 1210], edge_attr=[1210, 4], y=[32, 19], pos=[580, 3], idx=[32], name=[32], z=[580], batch=[580], ptr=[33])\n",
      "DataBatch(x=[581, 11], edge_index=[2, 1192], edge_attr=[1192, 4], y=[32, 19], pos=[581, 3], idx=[32], name=[32], z=[581], batch=[581], ptr=[33])\n",
      "DataBatch(x=[560, 11], edge_index=[2, 1152], edge_attr=[1152, 4], y=[32, 19], pos=[560, 3], idx=[32], name=[32], z=[560], batch=[560], ptr=[33])\n",
      "DataBatch(x=[589, 11], edge_index=[2, 1220], edge_attr=[1220, 4], y=[32, 19], pos=[589, 3], idx=[32], name=[32], z=[589], batch=[589], ptr=[33])\n",
      "DataBatch(x=[596, 11], edge_index=[2, 1236], edge_attr=[1236, 4], y=[32, 19], pos=[596, 3], idx=[32], name=[32], z=[596], batch=[596], ptr=[33])\n",
      "DataBatch(x=[587, 11], edge_index=[2, 1208], edge_attr=[1208, 4], y=[32, 19], pos=[587, 3], idx=[32], name=[32], z=[587], batch=[587], ptr=[33])\n",
      "DataBatch(x=[566, 11], edge_index=[2, 1164], edge_attr=[1164, 4], y=[32, 19], pos=[566, 3], idx=[32], name=[32], z=[566], batch=[566], ptr=[33])\n",
      "DataBatch(x=[565, 11], edge_index=[2, 1178], edge_attr=[1178, 4], y=[32, 19], pos=[565, 3], idx=[32], name=[32], z=[565], batch=[565], ptr=[33])\n",
      "DataBatch(x=[575, 11], edge_index=[2, 1194], edge_attr=[1194, 4], y=[32, 19], pos=[575, 3], idx=[32], name=[32], z=[575], batch=[575], ptr=[33])\n",
      "DataBatch(x=[567, 11], edge_index=[2, 1178], edge_attr=[1178, 4], y=[32, 19], pos=[567, 3], idx=[32], name=[32], z=[567], batch=[567], ptr=[33])\n",
      "DataBatch(x=[553, 11], edge_index=[2, 1132], edge_attr=[1132, 4], y=[32, 19], pos=[553, 3], idx=[32], name=[32], z=[553], batch=[553], ptr=[33])\n",
      "DataBatch(x=[599, 11], edge_index=[2, 1228], edge_attr=[1228, 4], y=[32, 19], pos=[599, 3], idx=[32], name=[32], z=[599], batch=[599], ptr=[33])\n",
      "DataBatch(x=[603, 11], edge_index=[2, 1252], edge_attr=[1252, 4], y=[32, 19], pos=[603, 3], idx=[32], name=[32], z=[603], batch=[603], ptr=[33])\n",
      "DataBatch(x=[570, 11], edge_index=[2, 1198], edge_attr=[1198, 4], y=[32, 19], pos=[570, 3], idx=[32], name=[32], z=[570], batch=[570], ptr=[33])\n",
      "DataBatch(x=[559, 11], edge_index=[2, 1154], edge_attr=[1154, 4], y=[32, 19], pos=[559, 3], idx=[32], name=[32], z=[559], batch=[559], ptr=[33])\n",
      "DataBatch(x=[587, 11], edge_index=[2, 1224], edge_attr=[1224, 4], y=[32, 19], pos=[587, 3], idx=[32], name=[32], z=[587], batch=[587], ptr=[33])\n",
      "DataBatch(x=[554, 11], edge_index=[2, 1150], edge_attr=[1150, 4], y=[32, 19], pos=[554, 3], idx=[32], name=[32], z=[554], batch=[554], ptr=[33])\n",
      "DataBatch(x=[576, 11], edge_index=[2, 1200], edge_attr=[1200, 4], y=[32, 19], pos=[576, 3], idx=[32], name=[32], z=[576], batch=[576], ptr=[33])\n",
      "DataBatch(x=[614, 11], edge_index=[2, 1240], edge_attr=[1240, 4], y=[32, 19], pos=[614, 3], idx=[32], name=[32], z=[614], batch=[614], ptr=[33])\n",
      "DataBatch(x=[585, 11], edge_index=[2, 1218], edge_attr=[1218, 4], y=[32, 19], pos=[585, 3], idx=[32], name=[32], z=[585], batch=[585], ptr=[33])\n",
      "DataBatch(x=[567, 11], edge_index=[2, 1172], edge_attr=[1172, 4], y=[32, 19], pos=[567, 3], idx=[32], name=[32], z=[567], batch=[567], ptr=[33])\n",
      "DataBatch(x=[594, 11], edge_index=[2, 1228], edge_attr=[1228, 4], y=[32, 19], pos=[594, 3], idx=[32], name=[32], z=[594], batch=[594], ptr=[33])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "each batch is considered a hugh graph with many nodes and edges,\n",
    "in EGNN, they introduce the concept of l2 distance between nodes, \n",
    "yet I am not including this (probably not) for now. \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "dataloader = DataLoader(data, batch_size=32, shuffle=True) \n",
    "for i , x in enumerate(dataloader):\n",
    "    print(x)\n",
    "    if i > 20: \n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[564, 11], edge_index=[2, 1136], edge_attr=[1136, 4], y=[32, 19], pos=[564, 3], idx=[32], name=[32], z=[564], batch=[564], ptr=[33])\n",
      "tensor([[  0,   0,   0,  ..., 561, 562, 563],\n",
      "        [  1,   8,   9,  ..., 554, 555, 556]])\n"
     ]
    }
   ],
   "source": [
    "print(dummy)\n",
    "print(dummy.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "# try the customized pyg model \n",
    "hidden_dim = 64 # hidden dimension\n",
    "n_feat_out = 7 # output latent embedding shape\n",
    "n_layers = 4\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "num_epochs = 10 \n",
    "net = Net(n_feat_in=dummy.x.shape[1], hidden_dim=hidden_dim, n_feat_out= n_feat_out, device=device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(dataloader) as tepoch:\n",
    "        for data in tepoch:\n",
    "            optimizer.zero_grad()\n",
    "            data = data.to(device)\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node embedding \n",
    "\n",
    "Embedding the graph representation of the data. ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "# num_embeddings = the number of unique items that can be embed, types of atoms \n",
    "# embedding_dim = embedding dimension, the size of the embedding vector (latent space)\n",
    "\n",
    "embedding = nn.Embedding(num_embeddings = 10, embedding_dim = 3) \n",
    "# a batch of 2 samples of 4 indices each\n",
    "input = torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 9]])\n",
    "print(input.shape)\n",
    "e = embedding(input)\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
